{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 List three key differences between supervised learning and reinforcement learning:\n",
    "\n",
    "<span style=\"color: lightgreen;\" >\n",
    "<ul style=\"display: flex; flex-direction: column; gap: 10px;\">\n",
    "<li style=\"list-style-type: numeber;\"> Supervised learning uses labeled training data with correct input-output pairs to train the model. Reinforcement learning uses no labeled data and that the agent learns from rewards/penalties through interaction with the environment.\n",
    "<li style=\"list-style-type: number;\"> Supervised learning is a one-step process where the model learns direct mappings from inputs to outputs while reinforcement learning is a sequential decision-making process where current actions do affect future states and rewards.\n",
    "<li style=\"list-style-type: number;\"> Supervised learning aims to minimize the KL divergence between the predicted and true distributions(equivalent to maximize the log-likelihood) while reinforcement learning aims to maximize expected or cumulative rewards over time through trial and error, it's like exploring the environment and learning from the feedback.\n",
    "</ul>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 What is the name of the function that maps specific states to specific actions?\n",
    "\n",
    "<span style=\"color: lightgreen;\" >\n",
    "Policy function. This function could be deterministic or stochastic.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 What is a possible difference between what an RL agent observes and what defines its state at a given time step?\n",
    "\n",
    "<span style=\"color: lightgreen;\" >\n",
    "The dimension of the state space could be different from the dimension of the observation space. For example, the state space of a autonomous car could be defined as the position and velocity of the car since it minimally describes the car's state at any time step, while the observation could be that the car is moving forward. Generally speaking, the state space is the minimal set of variables that can describe the system, while the observation space is the set of variables that the agent can observe. In other words, the observation space can oftenly be partial compared to the full state space.\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 What is the difference between a deterinistic policy and a stochastic policy?\n",
    "\n",
    "<span style=\"color: lightgreen;\" >\n",
    "A deterministic policy maps each state to a single action, while a stochastic policy maps each state to a distribution over actions.\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 For each of the following scenarios, determine whether the given policy is deterministic or stochastic. Briefly justify your answer.\n",
    "\n",
    "<div style=\"display: flex; flex-direction: column; gap: 0px;\">\n",
    "(a) Scenario: A robot moves in a grid world.\n",
    "\n",
    "<span style=\"padding-left: 26px;\">Policy: The robot always moves right if possible; otherwise, it moves up.\n",
    "</span>\n",
    "\n",
    "<span style=\"padding-left: 26px; color: lightgreen;\">Answer: Deterministic policy. Since there is no randomness in the action taken, all the next step move is predictable.</span>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div style=\"display: flex; flex-direction: column; gap: 0px;\">\n",
    "(b) Scenario: A self-driving car is approaching an intersection.\n",
    "\n",
    "<span style=\"padding-left: 26px;\">Policy: The car chooses to turn left with 70% probability and right with 30% probability.\n",
    "</span>\n",
    "\n",
    "<span style=\"padding-left: 26px; color: lightgreen;\">Answer: Stochastic policy. Since at each state, the car can choose from two actions with certain probabilities, which you cannot predict.</span>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div style=\"display: flex; flex-direction: column; gap: 0px;\">\n",
    "(c) Scenario: A chess engine selects a move given a specific board state.\n",
    "\n",
    "<span style=\"padding-left: 26px;\">Policy: The engine always picks the move with the highest evaluation score.\n",
    "</span>\n",
    "\n",
    "<span style=\"padding-left: 26px; color: lightgreen;\">Answer: Deterministic policy. It's fully rule-based and is predictable.</span>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div style=\"display: flex; flex-direction: column; gap: 0px;\">\n",
    "(d) Scenario: A robot is navigating through rough terrain.\n",
    "\n",
    "<span style=\"padding-left: 26px;\">Policy: The robot chooses an action based on a probability distribution over safe movements.\n",
    "</span>\n",
    "\n",
    "<span style=\"padding-left: 26px; color: lightgreen;\">Answer: Stochastic policy. Since at each state, the robot can choose from multiple actions with certain probabilities, which you cannot predict.</span>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div style=\"display: flex; flex-direction: column; gap: 0px;\">\n",
    "(e) Scenario: A thermostat controls room temperature.\n",
    "\n",
    "<span style=\"padding-left: 26px;\">Policy: It turns the heater on when the tempature drops below 18°C and off when it rises above 22°C.\n",
    "</span>\n",
    "\n",
    "<span style=\"padding-left: 26px; color: lightgreen;\">Answer: Deterministic policy. It is fully rule-based and is predictable. Precisely, there is a injective mapping between the current state and the action.</span>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
